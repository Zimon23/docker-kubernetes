 Fluentd란?

  "데이터를 위한 만능 어댑터" 또는 "로그 데이터 배관공(Plumber)"이라고 생각하시면 쉽습니다.

  다양한 곳에서, 다양한 형식으로 발생하는 로그(log)나 이벤트 데이터를 수집(Collect)하고, 원하는 형태로 가공(Filter)하여, 지정된
  목적지로 안정적으로 전송(Output)해주는 오픈소스 데이터 수집기입니다.

  Fluentd가 해결하는 문제 (왜 필요한가?)

  현대의 애플리케이션 환경은 매우 복잡합니다. 예를 들어, 하나의 서비스를 운영하더라도 다음과 같이 여러 구성 요소가 각자의
  로그를 남깁니다.

   * 웹 서버 (Nginx, Apache)
   * 애플리케이션 서버 (Spring Boot, Node.js, Django)
   * 데이터베이스 (MySQL, PostgreSQL, MongoDB)
   * 컨테이너 (Docker, Kubernetes)
   * 운영체제 자체의 시스템 로그

  이 로그들은 저장되는 위치도, 형식도 모두 제각각입니다. 문제가 발생했을 때 원인을 찾거나, 서비스의 상태를 분석하려면 이 흩어진 로그들을 일일이 찾아다니며 분석해야 하는 어려움이 있습니다.

  Fluentd는 바로 이 문제를 해결하기 위해 등장했습니다.

  Fluentd의 작동 방식 (어떻게 동작하는가?)

  Fluentd는 크게 3단계의 파이프라인으로 동작하며, 각 단계는 플러그인(Plugin)을 통해 유연하게 확장할 수 있습니다.

  !Fluentd Architecture (https://docs.fluentd.org/images/fluentd-architecture.png)

   1. Input (입력): 어디에서 데이터를 가져올 것인가?
       * 로그 파일의 변경 사항을 감시 (tail)
       * HTTP 요청으로 데이터를 받음 (http)
       * TCP/UDP 소켓으로 데이터를 받음 (tcp, forward)
       * 시스템 저널 로그를 읽음 (systemd)
       * 수백 개의 입력 플러그인을 통해 거의 모든 데이터 소스를 지원합니다.

   2. Filter (가공/필터링): 가져온 데이터를 어떻게 처리할 것인가?
       * 정규표현식을 이용해 비정형 로그(e.g., [INFO] 2024-07-27 User 'admin' logged in.)를 정형화된 JSON 데이터로 변환 (parser)
       * 불필요한 필드를 제거 (record_transformer)
       * 특정 조건에 맞는 로그만 필터링 (grep)
       * 데이터에 새로운 정보(e.g., 서버 IP, 태그)를 추가 (record_transformer)

   3. Output (출력): 처리된 데이터를 어디로 보낼 것인가?
       * 데이터 분석 시스템: Elasticsearch, Splunk, BigQuery
       * 클라우드 스토리지: Amazon S3, Google Cloud Storage
       * 메시지 큐: Kafka, RabbitMQ
       * 다른 Fluentd 서버로 전달
       * 마찬가지로 수백 개의 출력 플러그인을 통해 다양한 시스템과 연동됩니다.

  Fluentd의 핵심 특징 및 장점

   * 통합된 로깅 계층 (Unified Logging Layer): 흩어져 있는 로그를 한곳으로 모아 중앙에서 관리할 수 있게 해줍니다.
   * 유연한 플러그인 아키텍처: 500개 이상의 플러그인을 통해 원하는 거의 모든 시스템과 쉽게 연동할 수 있습니다.
   * 안정성: 메모리나 파일 기반의 버퍼(Buffer) 기능을 제공하여, 목적지 시스템에 장애가 발생하더라도 데이터 유실을 방지합니다.
   * 작은 리소스 사용량: C언어와 Ruby로 작성되어 성능이 뛰어나고 메모리 사용량이 적습니다.
   * CNCF 졸업 프로젝트: 클라우드 네이티브 컴퓨팅 재단(CNCF)의 졸업(Graduated) 프로젝트로, 안정성과 커뮤니티의 성숙도가
     검증되었습니다. (Prometheus, Kubernetes와 같은 등급)

  Fluentd vs Fluent Bit

   * Fluentd: 데이터 수집, 가공, 전송의 모든 기능을 갖춘 "만능 데이터 수집기". 복잡한 라우팅이나 데이터 가공이 필요한 중앙 집중형 서버에 적합합니다.
   * Fluent Bit: 경량화된 데이터 "전송기(Forwarder)". 리소스가 제한적인 엣지(Edge) 장비나 컨테이너 환경에서 로그를 수집하여 Fluentd 서버로 전달하는 역할에 최적화되어 있습니다.

  보통 Fluent Bit (수집) -> Fluentd (중앙 처리) -> Elasticsearch (저장/분석) 와 같은 조합으로 많이 사용됩니다.

  요약

  Fluentd는 복잡한 환경의 흩어진 로그 데이터를 한곳으로 모으고, 가공하여, 원하는 분석 시스템으로 안정적으로 보내주는 강력하고 유연한 데이터 수집 엔진입니다. 이를 통해 개발자와 운영자는 로그 데이터를 훨씬 쉽게 관리하고 분석할 수 있습니다.
  
  예제 시나리오 
  
  Nginx와 MySQL을 각각 2대씩 Docker 컨테이너로 실행하고, 이 서버들에서 발생하는 모든 로그를 Fluentd를 통해 수집하여 MongoDB에 저장하는 전체 구성 스크립트

  목표 아키텍처

   [Server 1]             [Server 2]
   - Nginx (nginx1)       - Nginx (nginx2)
   - MySQL (mysql1)       - MySQL (mysql2)
         |                      |
         +----------------------+
                      | (Docker Logging Driver)
                      v
               [Fluentd Server]
      (수집, 파싱) -> (MongoDB로 전송)
                      |
                      v
              [MongoDB Server]
           (로그 데이터 최종 저장)

  1. 프로젝트 디렉토리 생성

  먼저 작업을 위한 디렉토리를 만들고 그 안으로 이동합니다.

   mkdir fluentd-mongo-logging-cli
   cd fluentd-mongo-logging-cli

  2. Docker 네트워크 생성

  모든 컨테이너가 서로 통신할 수 있도록 격리된 Docker 네트워크를 생성합니다. 이렇게 하면 컨테이너 이름을 호스트 이름처럼 사용하여 서로를 찾을 수 있습니다.

   docker network create logging-net

  3. Fluentd 설정 파일 생성

  Fluentd 컨테이너가 사용할 설정 파일을 생성합니다. 이 파일은 로그를 어디서 받아서(Input), 어떻게 가공하고(Filter), 어디로 보낼지(Output)를 정의합니다.

   # fluentd 설정 디렉토리 생성
   mkdir -p fluentd/conf

   # fluentd/log/buffer 디렉토리 생성 (버퍼 파일 저장용)
   mkdir -p fluentd/log/buffer
   
   # fluentd mongo 로그 기록 폴더 생성
   mkdir -p fluentd/log/buffer/mongo
   chmod -R a+w fluentd/log
   
   # fluentd.conf 파일 생성
cat <<EOF > fluentd/conf/fluent.conf
# ==== INPUT ====
# Docker 로깅 드라이버로부터 로그를 받습니다.
<source>
 @type forward
 port 24224
 bind 0.0.0.0
</source>

# ==== FILTER ====
# Nginx 로그를 JSON 형식으로 파싱합니다.
# tag가 "nginx.**"로 시작하는 로그에만 적용됩니다.
<filter nginx.**>
 @type parser
 key_name log
 <parse>
   @type nginx
 </parse>
</filter>

# MySQL 로그에 컨테이너 이름을 추가합니다.
# tag가 "mysql.**"로 시작하는 로그에만 적용됩니다.
<filter mysql.**>
 @type record_transformer
 <record>
   container_name ${tag_parts[2]}
 </record>
</filter>

# ==== OUTPUT ====
# 모든 로그(match '**')를 MongoDB로 보냅니다.
<match **>
 @type mongo

 # MongoDB 컨테이너의 호스트 이름(네트워크 내)
 host mongo-db
 port 27017

 # 데이터베이스와 컬렉션 이름
 database docker_logs
 collection ${tag} # 로그 태그별로 다른 컬렉션에 저장

 # 성능을 위해 Capped Collection 사용 (선택 사항)
 capped
 capped_size 1024m

 # 버퍼 설정 (Fluentd가 다운되어도 로그 유실 방지)
 <buffer>
   @type file
   path /fluentd/log/buffer/mongo
   flush_interval 10s
 </buffer>
</match>
EOF

  4. 모든 컨테이너 실행 스크립트

Docker 이미지 생성 파일 

cat <<EOF > Dockerfile.sh
#!/bin/bash
# fluentd/Dockerfile

# Use the official Fluentd image as a base
FROM fluent/fluentd:v1.14-1

# Switch to root user to install gems
USER root

# Install build dependencies, then install gems, then remove dependencies
RUN apk add --no-cache \
    build-base \
    ruby-dev \
    && gem install fluent-plugin-mongo -v 1.5.0 \
    && apk del build-base ruby-dev

# Switch back to the fluentd user
USER fluent
EOF


  이제 각 서비스를 Docker 컨테이너로 실행하는 셸 스크립트를 작성합니다.

cat <<EOF > start_all.sh
#!/bin/bash

# 스크립트 실행 중 오류 발생 시 즉시 중단
set -e

#Build the custom Fluentd image
docker build -t fluentd-mongo ./fluentd

echo "### 1. Starting MongoDB Container ###"
docker run -d  --name mongo-db  --network logging-net  -p 27017:27017  mongo:5.0

echo "### 2. Starting Fluentd Container ###"
# fluentd/log/buffer 디렉토리 생성 (버퍼 파일 저장용)
mkdir -p fluentd/log/buffer

docker run -d  --name fluentd-aggregator  --network logging-net  -p 24224:24224  -p 24224:24224/udp  -v "/home/kosa/fluentd-mongo-logging-cli/fluentd/conf:/fluentd/etc"  -v "/home/kosa/fluentd-mongo-logging-cli/fluentd/log/buffer:/fluentd/log/buffer"  fluentd-mongo

# Fluentd가 시작될 시간을 잠시 줍니다.
echo "Waiting for Fluentd to start..."
sleep 10

echo "### 3. Starting Nginx Containers (x2) ###"
# Nginx 1
docker run -d  --name nginx1  --network logging-net  -p 8081:80  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="nginx.access.{{.Name}}"  nginx

# Nginx 2
docker run -d  --name nginx2  --network logging-net  -p 8082:80  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="nginx.access.{{.Name}}"  nginx

echo "### 4. Starting MySQL Containers (x2) ###"
# MySQL 1
docker run -d  --name mysql1  --network logging-net  -e MYSQL_ROOT_PASSWORD=mysecretpassword1  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="mysql.log.{{.Name}}"  mysql:8.0

# MySQL 2
docker run -d  --name mysql2  --network logging-net  -e MYSQL_ROOT_PASSWORD=mysecretpassword2  --log-driver=fluentd  --log-opt fluentd-address=localhost:24224  --log-opt tag="mysql.log.{{.Name}}"  mysql:8.0

echo "### All containers are starting! ###"
docker ps
EOF

  5. 실행 및 확인

  1. 스크립트 실행 권한 부여 및 실행

   chmod +x start_all.sh
   ./start_all.sh

  2. Nginx 로그 생성

  웹 브라우저나 curl을 사용하여 각 Nginx 서버에 접속하여 로그를 발생시킵니다.

   curl http://localhost:8081
   curl http://localhost:8082
   curl http://localhost:8081/non-existent-page  # 404 에러 로그 생성

  3. MongoDB에서 로그 확인

  MongoDB 컨테이너에 접속하여 Fluentd가 저장한 로그를 확인합니다.

    # 1. MongoDB 컨테이너의 대화형 셸에 접속
    docker exec -it mongo-db mongosh
   
    # 2. MongoDB 셸에서 아래 명령어 실행
    # 데이터베이스 목록 확인
    show dbs
    # "docker_logs" 데이터베이스로 전환
    use docker_logs
    # 컬렉션(테이블) 목록 확인 (태그별로 생성됨)
    show collections
    # Nginx 로그 확인
    db.getCollection("nginx.access.nginx1").find().pretty()
    db.getCollection("nginx.access.nginx2").find().pretty()
    # MySQL 로그 확인
    db.getCollection("mysql.log.mysql1").find().pretty()

  exit를 입력하여 MongoDB 셸을 빠져나올 수 있습니다.

  6. 정리 스크립트

  모든 컨테이너와 네트워크를 한 번에 중지하고 삭제하는 스크립트입니다.

  cat <<EOF > stop_all.sh

    #!/bin/bash
    set -e
   
    echo "### Stopping and removing all containers... ###"
    docker stop mongo-db fluentd-aggregator nginx1 nginx2 mysql1 mysql2
    docker rm mongo-db fluentd-aggregator nginx1 nginx2 mysql1 mysql2
   
    echo "### Removing Docker network... ###"
    docker network rm logging-net
   
    echo "### Cleanup complete! ###"
  EOF

  정리 스크립트 실행

   1 chmod +x stop_all.sh
   2 ./stop_all.sh

  이제 순수 Docker 명령어만으로 전체 로깅 시스템을 구성하고, 테스트하고, 정리할 수 있습니다. 
  
  
