NFS, Nginx를 연동하여 확장 가능하고 안정적인 웹 서비스를 구축하는 방법

1단계: 사전 준비 및 계획

먼저, 3대의 리눅스 서버가 준비되어야 합니다. 이 가이드에서는 Ubuntu 24.04 LTS를 기준으로
설명합니다.

서버 역할을 다음과 같이 정하겠습니다.

┌───────────────┬────────────────────────────────────┬────────────────┐
│ 서버 호스트명 │ 역할                               │ IP 주소 (예시) │
├───────────────┼────────────────────────────────────┼────────────────┤
│ server-a      │ 마스터 + NFS 서버                  │ 192.168.0.10   │
│ server-b      │ 워커 + NFS 클라이언트              │ 192.168.0.11   │
│ server-c      │ 워커 + NFS 클라이언트              │ 192.168.0.12   │
└───────────────┴────────────────────────────────────┴────────────────┘

2단계: NFS 서버 설정 (server-a에서 실행)

Nginx의 HTML 파일들을 저장하고 모든 노드에 공유해 줄 NFS 서버를 server-a에 구성합니다.

 1. NFS 서버, vim 패키지 설치
```
sudo apt-get update
sudo apt-get install -y nfs-kernel-server
```
 2. 공유할 디렉토리 생성
    이 디렉토리가 Nginx의 웹 루트 디렉토리가 됩니다  
```   
sudo mkdir -p /mnt/nfs/html
```
 3. 디렉토리 권한 설정
    NFS 공유를 위해 디렉토리 소유자를 nobody:nogroup으로 변경합니다.
```
sudo chown nobody:nogroup /mnt/nfs/html
sudo chmod 777 /mnt/nfs/html
```
 4. NFS 공유 설정 파일 수정
    /etc/exports 파일에 어떤 디렉토리를 누구에게 공유할지 설정합니다.
```
sudo vi /etc/exports
```
 파일 맨 아래에 다음 내용을 추가합니다. 특정 IP 대역 192.168.0.0/24을 입력하세요.
```
/mnt/nfs/html *(rw,sync,no_subtree_check,no_root_squash)
```
 5. NFS 설정 적용 및 서비스 재시작
```
sudo exportfs -a
sudo systemctl restart nfs-kernel-server
```
 6. 테스트용 HTML 파일 생성
    나중에 Nginx가 잘 작동하는지 확인하기 위해 간단한 index.html 파일을 만들어 둡니다.
```
echo "<h1>Hello from NFS Server</h1>" | sudo tee /mnt/nfs/html/index.html
```

이제 server-a는 NFS 서버로서 /mnt/nfs/html 디렉토리를 공유할 준비가 되었습니다.

3단계: NFS 클라이언트 설정 (server-b, server-c에서 실행)

워커 노드들이 NFS 서버의 공유 폴더를 자신의 로컬 폴더처럼 사용하기 위한 설정입니다. 
아래 과정은 `server-b`와 `server-c` 두 서버 모두에서 각각 실행해야 합니다.

 1. NFS 클라이언트, vim 패키지 설치
```
sudo apt-get update
sudo apt-get install -y nfs-common
```
 2. 마운트할 로컬 디렉토리 생성
    NFS 공유 폴더를 연결할 로컬 디렉토리를 만듭니다.
```
sudo mkdir -p /mnt/nfs/html
```

 3. NFS 공유 폴더 마운트 부팅 시 자동 마운트 설정
    서버가 재부팅되어도 NFS 공유 폴더가 자동으로 마운트되도록 /etc/fstab에 등록합니다.
```
sudo vi /etc/fstab

192.168.0.10:/mnt/nfs/html    /mnt/nfs/html   nfs auto,nofail,noatime,nolock,intr,tcp,actimeo=1800 0 0
```

 6. 설정 적용
    테스트 마운트를 해제하고 fstab 설정으로 다시 마운트합니다.
```
sudo mount -a
df -h
```

다시 df -h로 확인했을 때 마운트가 되어있다면 성공입니다.

4단계 : nginx에 html 파일을 nfs 폴더로 공유하기   

폴더 구조 

nfs-exam/
├── nfs-deployment.yaml
├── nfs-pv.yaml
├── nfs-pvc.yaml
└── nfs-service.yaml

  이제부터는 kubectl을 사용하는 PC에서 YAML 파일을 생성하고 클러스터에 적용합니다.

  4.1. PersistentVolume (PV) 생성
  클러스터에 우리가 방금 만든 NFS 공유 디렉터리가 "사용 가능한 스토리지"임을 알려주는 PV를 생성합니다.

  중요: 아래 YAML 파일에서 <MASTER_NODE_IP> 부분을 실제 Master 노드의 IP 주소로 반드시
  변경해주세요.

  nfs-pv.yaml 파일을 생성합니다.
```
#vi nfs-pv.yaml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    # NFS 서버의 공유 디렉터리 경로
    path: /mnt/nfs/html
    # 중요: 이 부분을 실제 Master 노드의 IP 주소로 변경하세요!
    server: 192.168.80.159

```

4.1. PersistentVolumeClaim (PVC) 생성
NGINX 파드가 사용할 스토리지에 대한 "요청"을 나타내는 PVC를 생성합니다. 이 PVC는 위에서 정의한
 nfs-pv에 바인딩(연결)될 것입니다.

  nfs-pvc.yaml 파일을 생성합니다.
```
#nfs-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi

```

 4.3. NGINX Deployment 생성
  이제 NGINX 파드를 배포합니다. 이 Deployment는 3개의 NGINX 파드를 생성하며, 각 파드는 위에서
  생성한 nfs-pvc를 통해 NFS 공유 디렉터리를 /usr/share/nginx/html 경로에 마운트합니다. NGINX는 이
  경로에서 index.html 파일을 읽어 서비스하게 됩니다.

nfs-deployment.yaml 파일을 생성합니다.
```
#vi nfs-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
          volumeMounts:
            - name: nfs-storage
              mountPath: /usr/share/nginx/html
      volumes:
        - name: nfs-storage
          persistentVolumeClaim:
            claimName: nfs-pvc

```

4.4. Service 생성
  NGINX 파드에 접근할 수 있도록 Service를 생성합니다. 여기서는 NodePort 타입을 사용하여 클러스터 외부에서 특정 노드의 포트를 통해 NGINX에 접근할 수 있도록 합니다.

nfs-service.yaml 파일을 생성합니다.
```
#vi nfs-service.yaml

apiVersion: v1
kind: Service
metadata:
  name: nfs-nginx-service
spec:
  selector:
    app: nginx
  type: NodePort
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080 # 30000-32767 범위 내에서 사용 가능한 포트

```

5. Kubernetes 리소스 배포 및 확인

  이제 모든 YAML 파일이 준비되었습니다. 클러스터에 배포하고 정상적으로 작동하는지 확인합니다.

  5.1. PV, PVC, Deployment, Service 생성
  생성한 YAML 파일들을 순서대로 클러스터에 적용합니다.
```
kubectl apply -f nfs-pv.yaml
kubectl apply -f nfs-pvc.yaml
kubectl apply -f nfs-deployment.yaml
kubectl apply -f nfs-service.yaml
```

  5.2. 배포 상태 확인
  파드와 디플로이먼트가 정상적으로 생성되고 실행 중인지 확인합니다.

```
kubectl get pv
kubectl get pvc
kubectl get deployment nfs-nginx-deployment
kubectl get pods -l app=nginx
```
   * kubectl get pv 결과에서 nfs-pv의 상태가 Bound로 표시되어야 합니다.
   * kubectl get pvc 결과에서 nfs-pvc의 상태가 Bound로 표시되어야 합니다.
   * kubectl get deployment 결과에서 nfs-nginx-deployment의 READY가 3/3으로 표시되어야 합니다.
   * kubectl get pods 결과에서 3개의 NGINX 파드가 모두 Running 상태여야 합니다.

  5.3. 서비스 확인 및 접속 테스트
  NGINX 서비스가 정상적으로 노출되었는지 확인하고 웹 브라우저나 curl 명령어로 접속 테스트를
  합니다.
```
kubectl get svc nfs-nginx-service
```
  위 명령어의 출력에서 nfs-nginx-service의 TYPE이 NodePort이고, PORT(S)에 80:30080/TCP와 같이
  NodePort가 할당된 것을 확인할 수 있습니다. (여기서는 30080으로 지정했습니다.)

  이제 클러스터의 어떤 Worker 노드의 IP 주소와 할당된 NodePort를 사용하여 웹 브라우저나 curl로
  접속해봅니다.
```
# <WORKER_NODE_IP>는 node1 또는 node2의 IP 주소입니다.
curl http://<WORKER_NODE_IP>:30080
```
  이 명령어를 실행하면 Master 노드의 /mnt/nfs/html/index.html 파일에 작성했던 내용이 출력되어야
  합니다.
```
curl 192.168.80.159:30080
<h1>Hello from NFS Server</h1>
```
이것으로 Master 노드의 NFS 서버를 통해 NGINX 파드들이 공유 스토리지를 성공적으로 사용하는 예제가 완성되었습니다.


  5.14. PV, PVC, Deployment, Service 삭제
  생성한 YAML 파일들을 순서대로 클러스터에 적용합니다.
```
kubectl delete -f nfs-pv.yaml
kubectl delete -f nfs-pvc.yaml
kubectl delete -f nfs-deployment.yaml
kubectl delete -f nfs-service.yaml
```

